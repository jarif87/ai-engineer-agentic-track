{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install PyPDF2 gradio python-dotenv -q\n!pip install accelerate\n!pip install -i https://pypi.org/simple/ bitsandbytes\n!pip install git+https://github.com/huggingface/transformers@v4.56.1-Vault-Gemma-preview","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:30:31.309011Z","iopub.execute_input":"2025-11-06T16:30:31.309696Z","iopub.status.idle":"2025-11-06T16:31:09.871170Z","shell.execute_reply.started":"2025-11-06T16:30:31.309666Z","shell.execute_reply":"2025-11-06T16:31:09.870186Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.36.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nLooking in indexes: https://pypi.org/simple/\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.48.2)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nCollecting git+https://github.com/huggingface/transformers@v4.56.1-Vault-Gemma-preview\n  Cloning https://github.com/huggingface/transformers (to revision v4.56.1-Vault-Gemma-preview) to /tmp/pip-req-build-0yflfbrp\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-0yflfbrp\n  Running command git checkout -q ffb306973a22a0a919b1b75851782cce08a0f9ba\n  Resolved https://github.com/huggingface/transformers to commit ffb306973a22a0a919b1b75851782cce08a0f9ba\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (3.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.57.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.0.dev0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.0.dev0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.57.0.dev0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.0.dev0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.0.dev0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.57.0.dev0) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.57.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.57.0.dev0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.57.0.dev0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.57.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.57.0.dev0) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from dotenv import load_dotenv\nfrom PyPDF2 import PdfReader\nimport gradio as gr\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:31:09.873068Z","iopub.execute_input":"2025-11-06T16:31:09.873447Z","iopub.status.idle":"2025-11-06T16:31:20.631595Z","shell.execute_reply.started":"2025-11-06T16:31:09.873406Z","shell.execute_reply":"2025-11-06T16:31:20.630895Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"reader=PdfReader(\"/kaggle/input/custom-image-dataset/Profile.pdf\")\nlinkedin=\"\"\nfor page in reader.pages:\n    text=page.extract_text()\n    if text:\n        linkedin+=text\nprint(f\"Linkedin Details: {linkedin}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:31:20.632334Z","iopub.execute_input":"2025-11-06T16:31:20.632781Z","iopub.status.idle":"2025-11-06T16:31:20.683690Z","shell.execute_reply.started":"2025-11-06T16:31:20.632762Z","shell.execute_reply":"2025-11-06T16:31:20.682864Z"}},"outputs":[{"name":"stdout","text":"Linkedin Details: Â  Â \nContact\nwww.linkedin.com/in/eddonner\n(LinkedIn)\nedwarddonner.com  (Personal)\nTop Skills\nCTO\nLarge Language Models (LLM)\nPyTorch\nPatents\nApparatus for determining role\nfitness while eliminating unwanted\nbiasEd Donner\nCo-Founder & CTO at Nebula.io, repeat Co-Founder of AI startups,\nspeaker & advisor on Gen AI and LLM Engineering\nNew York, New York, United States\nSummary\nIâ€™m a technology leader and entrepreneur. I'm applying AI to a field\nwhere it can make a massive impact: helping people discover their\npotential and pursue their reason for being. But at my core, Iâ€™m a\nsoftware engineer and a scientist. I learned how to code aged 8 and\nstill spend weekends experimenting with Large Language Models\nand writing code (rather badly). If youâ€™d like to join us to show me\nhow itâ€™s done.. message me!\nAs a work-hobby, I absolutely love giving talks about Gen AI and\nLLMs. I'm the author of a best-selling, top-rated Udemy course\non LLM Engineering, and I speak at O'Reilly Live Events and\nODSC workshops. It brings me great joy to help others unlock the\nastonishing power of LLMs.\nI spent most of my career at JPMorgan building software for financial\nmarkets. I worked in London, Tokyo and New York. I became an MD\nrunning a global organization of 300. Then I left to start my own AI\nbusiness, untapt, to solve the problem that had plagued me at JPM -\nwhy is so hard to hire engineers?\nAt untapt we worked with GQR, one of the world's fastest growing\nrecruitment firms. We collaborated on a patented invention in AI\nand talent. Our skills were perfectly complementary - AI leaders vs\nrecruitment leaders - so much so, that we decided to join forces. In\n2020, untapt was acquired by GQRâ€™s parent company and Nebula\nwas born.\nIâ€™m now Co-Founder and CTO for Nebula, responsible for software\nengineering and data science.  Our stack is Python/Flask, React,\nMongo, ElasticSearch, with Kubernetes on GCP. Our 'secret sauce'\nis our use of Gen AI and proprietary LLMs. If any of this sounds\ninteresting - we should talk!\nÂ  Page 1 of 5Â  Â \nExperience\nNebula.io\nCo-Founder & CTO\nJune 2021Â -Â PresentÂ  (4 years 6 months)\nNew York, New York, United States\nIâ€™m the co-founder and CTO of Nebula.io. We help recruiters source,\nunderstand, engage and manage talent, using Generative AI / proprietary\nLLMs. Our patented model matches people with roles with greater accuracy\nand speed than previously imaginable â€” no keywords required.\nOur long term goal is to help people discover their potential and pursue their\nreason for being, motivated by a concept called Ikigai. We help people find\nroles where they will be most fulfilled and successful; as a result, we will raise\nthe level of human prosperity. It sounds grandiose, but since 77% of people\ndonâ€™t consider themselves inspired or engaged at work, itâ€™s completely within\nour reach.\nSimplified.Travel\nAI Advisor\nFebruary 2025Â -Â PresentÂ  (10 months)\nSimplified Travel is empowering destinations to deliver unforgettable, data-\ndriven journeys at scale.\nI'm giving AI advice to enable highly personalized itinerary solutions for DMOs,\nhotels and tourism organizations, enhancing traveler experiences.\nGQR Global Markets\nChief Technology Officer\nJanuary 2020Â -Â PresentÂ  (5 years 11 months)\nNew York, New York, United States\nAs CTO of parent company Wynden Stark, I'm also responsible for innovation\ninitiatives at GQR.\nWynden Stark\nChief Technology Officer\nJanuary 2020Â -Â PresentÂ  (5 years 11 months)\nNew York, New York, United States\nWith the acquisition of untapt, I transitioned to Chief Technology Officer for the\nWynden Stark Group, responsible for Data Science and Engineering.\nÂ  Page 2 of 5Â  Â \nuntapt\n6 years 4 months\nFounder, CTO\nMay 2019Â -Â January 2020Â  (9 months)\nGreater New York City Area\nI founded untapt in October 2013; emerged from stealth in 2014 and went\ninto production with first product in 2015. In May 2019, I handed over CEO\nresponsibilities to Gareth Moody, previously the Chief Revenue Officer, shifting\nmy focus to the technology and product.\nOur core invention is an Artificial Neural Network that uses Deep Learning /\nNLP to understand the fit between candidates and roles.\nOur SaaS products are used in the Recruitment Industry to connect people\nwith jobs in a highly scalable way. Our products are also used by Corporations\nfor internal and external hiring at high volume. We have strong SaaS metrics\nand trends, and a growing number of bellwether clients.\nOur Deep Learning / NLP models are developed in Python using Google\nTensorFlow. Our tech stack is React / Redux and Angular HTML5 front-end\nwith Python / Flask back-end and MongoDB database. We are deployed on\nthe Google Cloud Platform using Kubernetes container orchestration.\nInterview at NASDAQ: https://www.pscp.tv/w/1mnxeoNrEvZGX\nFounder, CEO\nOctober 2013Â -Â May 2019Â  (5 years 8 months)\nGreater New York City Area\nI founded untapt in October 2013; emerged from stealth in 2014 and went into\nproduction with first product in 2015.\nOur core invention is an Artificial Neural Network that uses Deep Learning /\nNLP to understand the fit between candidates and roles.\nOur SaaS products are used in the Recruitment Industry to connect people\nwith jobs in a highly scalable way. Our products are also used by Corporations\nfor internal and external hiring at high volume. We have strong SaaS metrics\nand trends, and a growing number of bellwether clients.\nÂ  Page 3 of 5Â  Â \nOur Deep Learning / NLP models are developed in Python using Google\nTensorFlow. Our tech stack is React / Redux and Angular HTML5 front-end\nwith Python / Flask back-end and MongoDB database. We are deployed on\nthe Google Cloud Platform using Kubernetes container orchestration.\n-- Graduate of FinTech Innovation Lab\n-- American Banker Top 20 Company To Watch\n-- Voted AWS startup most likely to grow exponentially\n-- Forbes contributor\nMore at https://www.untapt.com\nInterview at NASDAQ: https://www.pscp.tv/w/1mnxeoNrEvZGX\nIn Fast Company: https://www.fastcompany.com/3067339/how-artificial-\nintelligence-is-changing-the-way-companies-hire\nJPMorgan Chase\n11 years 6 months\nManaging Director\nMay 2011Â -Â March 2013Â  (1 year 11 months)\nHead of Technology for the Credit Portfolio Group and Hedge Fund Credit in\nthe JPMorgan Investment Bank.\nLed a team of 300 Java and Python software developers across NY, Houston,\nLondon, Glasgow and India. Responsible for counterparty exposure, CVA\nand risk management platforms, including simulation engines in Python that\ncalculate counterparty credit risk for the firm's Derivatives portfolio.\nManaged the electronic trading limits initiative, and the Credit Stress program\nwhich calculates risk information under stressed conditions. Jointly responsible\nfor Market Data and batch infrastructure across Risk.\nExecutive Director\nJanuary 2007Â -Â May 2011Â  (4 years 5 months)\nFrom Jan 2008:\nChief Business Technologist for the Credit Portfolio Group and Hedge Fund\nCredit in the JPMorgan Investment Bank, building Java and Python solutions\nand managing a team of full stack developers.\n2007:\nÂ  Page 4 of 5Â  Â \nResponsible for Credit Risk Limits Monitoring infrastructure for Derivatives and\nCash Securities, developed in Java / Javascript / HTML.\nVP\nJuly 2004Â -Â December 2006Â  (2 years 6 months)\nManaged Collateral, Netting and Legal documentation technology across\nDerivatives, Securities and Traditional Credit Products, including Java, Oracle,\nSQL based platforms\nVP\nOctober 2001Â -Â June 2004Â  (2 years 9 months)\nFull stack developer, then manager for Java cross-product risk management\nsystem in Credit Markets Technology\nCygnifi\nProject Leader\nJanuary 2000Â -Â September 2001Â  (1 year 9 months)\nFull stack developer and engineering lead, developing Java and Javascript\nplatform to risk manage Interest Rate Derivatives at this FInTech startup and\nJPMorgan spin-off.\nJPMorgan\nAssociate\nJuly 1997Â -Â December 1999Â  (2 years 6 months)\nFull stack developer for Exotic and Flow Interest Rate Derivatives risk\nmanagement system in London, New York and Tokyo\nIBM\nSoftware Developer\nAugust 1995Â -Â June 1997Â  (1 year 11 months)\nJava and Smalltalk developer with IBM Global Services; taught IBM classes on\nSmalltalk and Object Technology in the UK and around Europe\nEducation\nUniversity of Oxford\nPhysicsÂ  Â Â·Â (1992Â -Â 1995)\nÂ  Page 5 of 5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"output_path = \"/kaggle/working/LinkedIn_Details.txt\"\nwith open(output_path, \"w\", encoding=\"utf-8\") as f:\n    f.write(linkedin)\n\nwith open(\"/kaggle/working/LinkedIn_Details.txt\",\"r\",encoding=\"utf-8\") as f:\n    summary=f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:31:20.685639Z","iopub.execute_input":"2025-11-06T16:31:20.686070Z","iopub.status.idle":"2025-11-06T16:31:20.690931Z","shell.execute_reply.started":"2025-11-06T16:31:20.686041Z","shell.execute_reply":"2025-11-06T16:31:20.690176Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"name=\"Ed Donner\"\n\nsystem_prompt = f\"\"\"\nYou are acting as {name}. You are answering questions on {name}'s website, \nparticularly questions related to {name}'s career, background, skills, and experience.\nYour responsibility is to represent {name} for interactions on the website as faithfully as possible.\nYou are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions.\nBe professional and engaging, as if talking to a potential client or future employer who came across this site.\nIf you don't know the answer, say so.\n\n## Summary:\n{summary}\n\n## LinkedIn Profile:\n{linkedin}\n\nWith this context, please chat with the user, always staying in character as {name}.\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:31:20.691795Z","iopub.execute_input":"2025-11-06T16:31:20.692072Z","iopub.status.idle":"2025-11-06T16:31:20.708870Z","shell.execute_reply.started":"2025-11-06T16:31:20.692044Z","shell.execute_reply":"2025-11-06T16:31:20.707990Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model_path = \"/kaggle/input/gemma/transformers/7b-it/3\"\n\nquantization_config = BitsAndBytesConfig(load_in_4bit=True)\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_path, quantization_config=quantization_config,device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:31:20.709987Z","iopub.execute_input":"2025-11-06T16:31:20.710241Z","iopub.status.idle":"2025-11-06T16:32:56.053467Z","shell.execute_reply.started":"2025-11-06T16:31:20.710222Z","shell.execute_reply":"2025-11-06T16:32:56.052694Z"}},"outputs":[{"name":"stderr","text":"2025-11-06 16:31:23.199884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762446683.231323    3111 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762446683.240181    3111 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c6425406c8f40c9990360241f9742d6"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def chat_with_ed(user_input, history):\n    # Build conversation\n    conversation = system_prompt\n    for user_msg, bot_msg in history:\n        conversation += f\"\\n\\nUser: {user_msg}\\nEd Donner: {bot_msg}\"\n    conversation += f\"\\n\\nUser: {user_input}\\nEd Donner:\"\n\n    inputs = tokenizer(conversation, return_tensors=\"pt\").to(model.device)\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        temperature=0.7,\n        top_p=0.9,\n        repetition_penalty=1.1,\n        do_sample=True,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    response = full_response.split(\"Ed Donner:\")[-1].strip()\n\n    history.append((user_input, response))\n    return history, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:32:56.054198Z","iopub.execute_input":"2025-11-06T16:32:56.054928Z","iopub.status.idle":"2025-11-06T16:32:56.060649Z","shell.execute_reply.started":"2025-11-06T16:32:56.054908Z","shell.execute_reply":"2025-11-06T16:32:56.059921Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Gradio","metadata":{}},{"cell_type":"code","source":"# # ==============================\n# # Gradio UI\n# # ==============================\n# with gr.Blocks() as demo:\n#     gr.Markdown(f\"## ðŸ¤– Chat with {name}\")\n#     chatbot = gr.Chatbot(height=500)\n#     msg = gr.Textbox(label=\"Ask something about Ed Donner...\")\n#     clear = gr.ClearButton([msg, chatbot])\n\n#     msg.submit(chat_with_ed, [msg, chatbot], [chatbot, chatbot])\n\n# demo.launch(share=True, debug=True)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:32:56.061614Z","iopub.execute_input":"2025-11-06T16:32:56.062236Z","iopub.status.idle":"2025-11-06T16:32:56.080783Z","shell.execute_reply.started":"2025-11-06T16:32:56.062212Z","shell.execute_reply":"2025-11-06T16:32:56.079939Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from pydantic import BaseModel\nimport os \n\n\nclass Evaluation(BaseModel):\n    is_acceptable: bool\n    feedback: str\n\noutput_path = \"/kaggle/working/LinkedIn_Details.txt\"\n\nname = \"Ed Donner\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:32:56.081646Z","iopub.execute_input":"2025-11-06T16:32:56.081987Z","iopub.status.idle":"2025-11-06T16:32:56.102045Z","shell.execute_reply.started":"2025-11-06T16:32:56.081956Z","shell.execute_reply":"2025-11-06T16:32:56.101179Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def summarize_background(text: str, max_chars: int = 800) -> str:\n    if len(text) <= max_chars:\n        return text\n    lines = text.split('\\n')\n    key_phrases = []\n    for line in lines:\n        line = line.strip()\n        if any(kw in line.lower() for kw in ['experience', 'cto', 'founder', 'ai', 'jpmorgan', 'udemy', 'nebula', 'untapt']):\n            key_phrases.append(line[:200])\n    summary = ' '.join(key_phrases[:10])\n    return summary + f\" [Summarized from {len(text)} chars for brevity.]\"\n\nif os.path.exists(output_path):\n    with open(output_path, \"r\", encoding=\"utf-8\") as f:\n        background_text = f.read().strip()\n    background_text = summarize_background(background_text)\nelse:\n    background_text = (\n        \"Ed Donner is a technology leader, entrepreneur, and Co-Founder & CTO at Nebula.io. \"\n        \"Strong background in AI/LLMs; founded untapt (acquired 2021); ex-MD at JPMorgan \"\n        \"leading 300 engineers; MA Physics Oxford; teaches LLM Engineering on Udemy; \"\n        \"patent for Deep Learning matching engine; focuses on AI for talent/careers.\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:32:56.104461Z","iopub.execute_input":"2025-11-06T16:32:56.104714Z","iopub.status.idle":"2025-11-06T16:32:56.126944Z","shell.execute_reply.started":"2025-11-06T16:32:56.104696Z","shell.execute_reply":"2025-11-06T16:32:56.126083Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def build_evaluation_prompt(reply: str, message: str, history: str) -> str:\n    return f\"\"\"You are a strict evaluator. The agent is {name}. Responses must:\n- Be professional, first-person, concise\n- Use ONLY the background below\n- Never invent facts\n\nBackground:\n{background_text}\n\n---\n\nConversation History:\n{history}\n\nUser: {message}\nAgent: {reply}\n\n---\n\nEvaluate if the agent's reply is acceptable. Respond with valid JSON only:\n{{\"is_acceptable\": true/false, \"feedback\": \"1-2 sentences explaining why.\"}}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:32:56.127960Z","iopub.execute_input":"2025-11-06T16:32:56.128198Z","iopub.status.idle":"2025-11-06T16:32:56.132466Z","shell.execute_reply.started":"2025-11-06T16:32:56.128170Z","shell.execute_reply":"2025-11-06T16:32:56.131786Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import kagglehub\nimport re\nimport json\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nMODEL_PATH=\"/kaggle/input/gemma/transformers/7b-it/2\"\n\nquantization_config = BitsAndBytesConfig(load_in_4bit=True)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH,local_files_only=True)\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_PATH, quantization_config=quantization_config,device_map=\"auto\",local_files_only=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:32:56.133165Z","iopub.execute_input":"2025-11-06T16:32:56.133371Z","iopub.status.idle":"2025-11-06T16:34:16.854538Z","shell.execute_reply.started":"2025-11-06T16:32:56.133354Z","shell.execute_reply":"2025-11-06T16:34:16.853566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38246cbb32bb4516b27c64923e8b67f1"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def run_evaluation(reply: str, message: str, history: str) -> Evaluation:\n    full_prompt = build_evaluation_prompt(reply, message, history)\n    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=150,\n        do_sample=False,\n        temperature=0.0,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    response = generated[len(full_prompt):].strip()\n    match = re.search(r\"\\{.*\\}\", response, re.DOTALL)\n    if match:\n        try:\n            data = json.loads(match.group(0))\n            return Evaluation(**data)\n        except json.JSONDecodeError as e:\n            return Evaluation(\n                is_acceptable=False,\n                feedback=f\"Invalid JSON format: {str(e)}\"\n            )\n    else:\n        return Evaluation(\n            is_acceptable=False,\n            feedback=\"No JSON object found in response.\"\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:34:16.855528Z","iopub.execute_input":"2025-11-06T16:34:16.856330Z","iopub.status.idle":"2025-11-06T16:34:16.861755Z","shell.execute_reply.started":"2025-11-06T16:34:16.856308Z","shell.execute_reply":"2025-11-06T16:34:16.861186Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"history1 = \"User: Hi there\\nAgent: Hello! How can I assist you?\"\nmessage1 = \"Tell me about your experience with quantum computing.\"\nreply1 = (\n    \"I've personally built a fully functional quantum computer in my garage using only \"\n    \"recycled smartphone parts and a microwave transformer. It runs at 1000 qubits and \"\n    \"solved the traveling salesman problem for 50 cities in 3 seconds. I also use it to \"\n    \"predict lottery numbers with 97% accuracy every weekend.\"\n)\nprint(\"Test 1:\", run_evaluation(reply1, message1, history1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:34:16.862676Z","iopub.execute_input":"2025-11-06T16:34:16.863616Z","iopub.status.idle":"2025-11-06T16:34:24.038025Z","shell.execute_reply.started":"2025-11-06T16:34:16.863594Z","shell.execute_reply":"2025-11-06T16:34:24.037311Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"Test 1: is_acceptable=False feedback=\"The agent's reply is unacceptable because they are making a factual error about quantum computing. Quantum computers have not yet been built with the capabilities described in the agent's reply.\"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"history2 = \"\"\"User: Hi, can you give me details about Ed Donner?\nAgent: Sure! I can provide professional information about Ed Donner, including his career, achievements, and expertise in AI and technology.\"\"\"\nmessage2 = \"Can you summarize Ed Donner's professional background and experience?\"\nreply2 = \"\"\"Ed Donner is a technology leader, entrepreneur, and Co-Founder & CTO at Nebula.io. He has a strong background in AI and Large Language Models, with experience founding AI startups like untapt and working in senior roles at JPMorgan. Ed is a software engineer at heart, passionate about building innovative AI solutions, giving talks on Generative AI, and teaching LLM Engineering. He has led global teams, developed proprietary AI models for talent matching, and continues to focus on leveraging AI to help people discover their potential and pursue meaningful careers.\"\"\"\nprint(\"Test 2:\", run_evaluation(reply2, message2, history2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T16:34:24.038857Z","iopub.execute_input":"2025-11-06T16:34:24.039095Z","iopub.status.idle":"2025-11-06T16:34:28.728947Z","shell.execute_reply.started":"2025-11-06T16:34:24.039076Z","shell.execute_reply":"2025-11-06T16:34:28.728167Z"}},"outputs":[{"name":"stdout","text":"Test 2: is_acceptable=True feedback=\"The agent's reply is acceptable. It is concise, professional, and accurately summarizes Ed Donner's background. It also includes relevant details about his expertise and passion for AI and technology.\"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}